[
  {
    "objectID": "ST558_Homework5.html#task-1-conceptual-questions",
    "href": "ST558_Homework5.html#task-1-conceptual-questions",
    "title": "ST558_Homework5",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\n1. What is the purpose of using cross-validation when fitting a random forest model?\n\nCross-validation provides a more reliable estimate of the model’s performance compared to using a single train-test split. It is used to choose the optimal tuning parameter and reduce bias and variance.\n\n\n\n2. Describe the bagged tree algorithm.\n\nThe bagged tree algorithm, or bootstrap aggregation, is an ensemble method that creates multiple datasets by resampling the original data with replacement (non-parametric) or from a fitted model (parametric). For each resampled dataset, a full decision tree is grown using all available features at each split. Predictions are made by aggregating results from all trees, using averaging for regression or majority voting for classification. Out-of-bag samples (observations not used in a particular bootstrap sample) are utilized to estimate model performance, providing robust error estimates and confidence intervals.\n\n\n\n3. What is meant by a general linear model?\n\nThe general linear model has continuous response and allows for both continuous and categorical predictors. It assumes a linear relationship between predictors and the expected value of the response.\n\n\n\n4. When fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\nWithout interaction terms, the model assumes that the effect of each predictor is constant, regardless of the values of other predictors. Interaction terms relax this assumption, allowing for more flexible and potentially more realistic modeling of complex relationships in the data. It allows the non-additive effects, which means the effect of one predictor can vary depending on the value of another predictor.\n\n\n\n5. Why do we split our data into a training and test set?\n\nWe split data into training and test sets to evaluate a model’s performance. It helps detect overfitting, assess generalization ability, and offers an unbiased performance estimate. The test set serves as a proxy for new data, allowing for fair model comparison and selection. It also prevents data leakage by keeping a portion of the data completely separate from the training process."
  },
  {
    "objectID": "ST558_Homework5.html#task-2-fitting-models",
    "href": "ST558_Homework5.html#task-2-fitting-models",
    "title": "ST558_Homework5",
    "section": "Task 2: Fitting Models",
    "text": "Task 2: Fitting Models\nThe data set called heart.csv is used for this task. This data set gives information about whether or not someone has heart disease (HeartDisease = 1 or = 0) along with different measurements about that person’s health.\n\nQuick EDA/Data Preparation\n\n# load required library\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\nlibrary(dplyr)\nlibrary(rpart)\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: 'randomForest'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(gbm)\n\nLoaded gbm 2.2.2\nThis version of gbm is no longer under development. Consider transitioning to gbm3, https://github.com/gbm-developers/gbm3\n\n\n\n# read in data\ndata &lt;- read_csv('heart.csv')\n\nRows: 918 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope\ndbl (7): Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak, HeartDisease\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n1. Check on missingness and summarize the data, especially with respect to the relationships of the variables to HeartDisease.\n\n# check missingness\ncolSums(is.na(data))\n\n           Age            Sex  ChestPainType      RestingBP    Cholesterol \n             0              0              0              0              0 \n     FastingBS     RestingECG          MaxHR ExerciseAngina        Oldpeak \n             0              0              0              0              0 \n      ST_Slope   HeartDisease \n             0              0 \n\n\nIt seems no NA values in this data. However, still some values seem not valid.\n\n# check zero values\ncolSums(data == 0)\n\n           Age            Sex  ChestPainType      RestingBP    Cholesterol \n             0              0              0              1            172 \n     FastingBS     RestingECG          MaxHR ExerciseAngina        Oldpeak \n           704              0              0              0            368 \n      ST_Slope   HeartDisease \n             0            410 \n\n\nThe resting blood pressure and serum cholesterol should not have a value of 0, thus they need to be dropped from the data. For fasting blood sugar and oldpeak, 0 is a possible value, thus, they are keeped.\n\n# drop the invalid data\ndata &lt;- data |&gt;\n  filter(!RestingBP == 0 & !Cholesterol == 0)\n\nAfter data cleaning, data is summaried to see the general pattern.\n\n# summarize data\nsummary(data)\n\n      Age            Sex            ChestPainType        RestingBP  \n Min.   :28.00   Length:746         Length:746         Min.   : 92  \n 1st Qu.:46.00   Class :character   Class :character   1st Qu.:120  \n Median :54.00   Mode  :character   Mode  :character   Median :130  \n Mean   :52.88                                         Mean   :133  \n 3rd Qu.:59.00                                         3rd Qu.:140  \n Max.   :77.00                                         Max.   :200  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   : 85.0   Min.   :0.0000   Length:746         Min.   : 69.0  \n 1st Qu.:207.2   1st Qu.:0.0000   Class :character   1st Qu.:122.0  \n Median :237.0   Median :0.0000   Mode  :character   Median :140.0  \n Mean   :244.6   Mean   :0.1676                      Mean   :140.2  \n 3rd Qu.:275.0   3rd Qu.:0.0000                      3rd Qu.:160.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:746         Min.   :-0.1000   Length:746         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.5000   Mode  :character   Median :0.0000  \n                    Mean   : 0.9016                      Mean   :0.4772  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n\nThe above information shows the distribution of numeric variables. However, the HeartDisease should be a 0-1 coded categorical variable. let’s correct it and see the distribution of categorical variables.\n\n# correct the data type of HeartDisease\ndata$HeartDisease &lt;- as.character(data$HeartDisease)\n# summarize data (for character variables)\ntable(data$Sex)\n\n\n  F   M \n182 564 \n\ntable(data$ChestPainType)\n\n\nASY ATA NAP  TA \n370 166 169  41 \n\ntable(data$RestingECG)\n\n\n   LVH Normal     ST \n   176    445    125 \n\ntable(data$ExerciseAngina)\n\n\n  N   Y \n459 287 \n\ntable(data$ST_Slope)\n\n\nDown Flat   Up \n  43  354  349 \n\ntable(data$HeartDisease)\n\n\n  0   1 \n390 356 \n\n\nGreat! The above information shows the distribution of the categorical variables. Then, we want to see the relationship between HeartDisease and the remaining variables. Let’s see the correlation plot. Prior to that, we need to convert categorical variables into dummy variables using dummyVars() and predict().\n\n# Convert categorical variables to dummy variables\ndata_dummy &lt;- dummyVars(\"~ .\", data = data)\ndata_transformed &lt;- data.frame(predict(data_dummy, newdata = data))\n\n# Calculate the correlation matrix\ncor_matrix &lt;- cor(data_transformed, use = \"complete.obs\")\n\n# Create the correlation plot\ncorrplot(cor_matrix, method = \"color\", \n         tl.cex = 0.8,\n         col = colorRampPalette(c(\"red\", \"white\", \"blue\"))(200),\n         type = \"upper\", \n         diag = FALSE)\n\n\n\n\n\n\n\n\nThe correlation plot shows HeartDisease1 is strongly and positively correlated with ChestPainTypeASY, ExerciseAnginaY, Oldpeak, ST_SlopeFlat, Age, and SexM. At the same time HeartDisease1 is strongly and negatively correlated with ST_SlopeUp, ExerciseAnginaN, MaxHR, ChestPainTypeATA, ChestPainTypeNAP, and SexF. Overall, whether a person has HeartDisease is related to his/her ExerciseAngina, Oldpeak, ST_Slope, ChestPainType, MaxHR, Sex, and Age.\n\n\n2. Create a new variable that is a factor version of the HeartDisease variable (if needed, this depends on how you read in your data). Remove the ST_Slope variable and the original HeartDisease variable (if applicable).\n\ndata_new &lt;- data_transformed |&gt;\n  mutate(HeartDisease = as.factor(HeartDisease0)) |&gt;\n  select(-ST_SlopeDown, -ST_SlopeUp, -ST_SlopeFlat, -HeartDisease0, -HeartDisease1)\n\n\n\n3. We’ll be doing a kNN model below to predict whether or not someone has heart disease. To use kNN we generally want to have all numeric predictors (although we could try to create our own loss function as an alternative). In this case we have some categorical predictors still in our data set: Sex, ExerciseAngina, ChestPainType, and RestingECG.Create dummy columns corresponding to the values of these four variables for use in our kNN fit.\nAt this point, the four categorical variables have already been transformed to dummy variables. It is ready for the kNN model.\n\nstr(data_new)\n\n'data.frame':   746 obs. of  18 variables:\n $ Age             : num  40 49 37 48 54 39 45 54 37 48 ...\n $ SexF            : num  0 1 0 1 0 0 1 0 0 1 ...\n $ SexM            : num  1 0 1 0 1 1 0 1 1 0 ...\n $ ChestPainTypeASY: num  0 0 0 1 0 0 0 0 1 0 ...\n $ ChestPainTypeATA: num  1 0 1 0 0 0 1 1 0 1 ...\n $ ChestPainTypeNAP: num  0 1 0 0 1 1 0 0 0 0 ...\n $ ChestPainTypeTA : num  0 0 0 0 0 0 0 0 0 0 ...\n $ RestingBP       : num  140 160 130 138 150 120 130 110 140 120 ...\n $ Cholesterol     : num  289 180 283 214 195 339 237 208 207 284 ...\n $ FastingBS       : num  0 0 0 0 0 0 0 0 0 0 ...\n $ RestingECGLVH   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ RestingECGNormal: num  1 1 0 1 1 1 1 1 1 1 ...\n $ RestingECGST    : num  0 0 1 0 0 0 0 0 0 0 ...\n $ MaxHR           : num  172 156 98 108 122 170 170 142 130 120 ...\n $ ExerciseAnginaN : num  1 1 1 0 1 1 1 1 0 1 ...\n $ ExerciseAnginaY : num  0 0 0 1 0 0 0 0 1 0 ...\n $ Oldpeak         : num  0 1 0 1.5 0 0 0 0 1.5 0 ...\n $ HeartDisease    : Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 2 2 2 2 1 2 ...\n\n\n\n\n\nSplit Data\n\nSplit data into a training and test set. I will use 80/20 split.\n\nset.seed(5580716)\n\ntrainIndex &lt;- createDataPartition(data_new$HeartDisease, p = .8,\n                                  list = FALSE,\n                                  times = 1)\n\ntraining_set &lt;-  data_new[trainIndex, ]\ntest_set &lt;- data_new[-trainIndex, ]\n\n#check data\ndim(training_set)\n\n[1] 597  18\n\ndim(test_set)\n\n[1] 149  18\n\n\n\n\n\nTrain the kNN model. Use repeated 10 fold cross-validation, with the number of repeats being 3.\n\n# Use repeated 10 fold cross-validation, with the number of repeats being 3. \ntrctrl &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)\nset.seed(55807161)\nknn_fit &lt;- train(HeartDisease ~., \n                 data = training_set, \n                 method = \"knn\",\n                 trControl=trctrl,\n                 preProcess = c(\"center\", \"scale\"), #preprocess the data\n                 tuneGrid = expand.grid(k = 1:40),\n                 tuneLength = 10)\nknn_fit\n\nk-Nearest Neighbors \n\n597 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 537, 538, 538, 536, 538, 538, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   1  0.7509371  0.5000291\n   2  0.7521421  0.5022997\n   3  0.7922114  0.5822427\n   4  0.7989719  0.5966304\n   5  0.8096505  0.6183091\n   6  0.8047146  0.6084138\n   7  0.8057978  0.6106429\n   8  0.7985379  0.5960863\n   9  0.7941393  0.5872720\n  10  0.8030573  0.6047404\n  11  0.7996669  0.5980992\n  12  0.8051769  0.6089993\n  13  0.8063436  0.6114314\n  14  0.8096213  0.6180180\n  15  0.8124468  0.6233701\n  16  0.8135479  0.6256798\n  17  0.8119186  0.6224741\n  18  0.8130203  0.6247162\n  19  0.8119186  0.6223906\n  20  0.8086038  0.6155765\n  21  0.8163633  0.6313645\n  22  0.8102325  0.6190560\n  23  0.8096863  0.6180717\n  24  0.8080285  0.6147284\n  25  0.8107883  0.6202272\n  26  0.8029726  0.6045378\n  27  0.8079635  0.6145153\n  28  0.8068709  0.6123385\n  29  0.8041116  0.6069732\n  30  0.8091314  0.6171107\n  31  0.8052419  0.6092233\n  32  0.8052789  0.6094364\n  33  0.8030658  0.6050089\n  34  0.8019641  0.6028756\n  35  0.8019641  0.6027902\n  36  0.8035934  0.6060378\n  37  0.8024823  0.6038011\n  38  0.8052786  0.6095102\n  39  0.8046954  0.6084098\n  40  0.8058348  0.6105405\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 21.\n\n\nIts showing Accuracy and Kappa metrics result for different k value. From the results, it automatically selects best k-value. Here, our training model is choosing k = 21 as its final value. Then, let’s predict classes for our test set and test its performance.\n\n# predict the test set with the trained model\ntest_pred &lt;- predict(knn_fit, newdata = test_set)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_kNN&lt;-confusionMatrix(test_pred, test_set$HeartDisease)\nconfusionMatrix_kNN\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 52 11\n         1 19 67\n                                          \n               Accuracy : 0.7987          \n                 95% CI : (0.7252, 0.8598)\n    No Information Rate : 0.5235          \n    P-Value [Acc &gt; NIR] : 2.755e-12       \n                                          \n                  Kappa : 0.5944          \n                                          \n Mcnemar's Test P-Value : 0.2012          \n                                          \n            Sensitivity : 0.7324          \n            Specificity : 0.8590          \n         Pos Pred Value : 0.8254          \n         Neg Pred Value : 0.7791          \n             Prevalence : 0.4765          \n         Detection Rate : 0.3490          \n   Detection Prevalence : 0.4228          \n      Balanced Accuracy : 0.7957          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nThe confusion matrix shows our model accuracy for the test set is 79.87%. It works pretty well.\n\n\nLogistic Regression. Based on EDA, posit three different logistic regression models.\nSince glm() could deal with the character predictors, thus, we will use data without dummy variables.\n\n# remove ST_Slope and change HeartDisease to factor data\ndata_logistic &lt;- data |&gt;\n  select(-ST_Slope) |&gt;\n  mutate(HeartDisease = as.factor(HeartDisease))\n# check data structure\nstr(data_logistic)\n\ntibble [746 × 11] (S3: tbl_df/tbl/data.frame)\n $ Age           : num [1:746] 40 49 37 48 54 39 45 54 37 48 ...\n $ Sex           : chr [1:746] \"M\" \"F\" \"M\" \"F\" ...\n $ ChestPainType : chr [1:746] \"ATA\" \"NAP\" \"ATA\" \"ASY\" ...\n $ RestingBP     : num [1:746] 140 160 130 138 150 120 130 110 140 120 ...\n $ Cholesterol   : num [1:746] 289 180 283 214 195 339 237 208 207 284 ...\n $ FastingBS     : num [1:746] 0 0 0 0 0 0 0 0 0 0 ...\n $ RestingECG    : chr [1:746] \"Normal\" \"Normal\" \"ST\" \"Normal\" ...\n $ MaxHR         : num [1:746] 172 156 98 108 122 170 170 142 130 120 ...\n $ ExerciseAngina: chr [1:746] \"N\" \"N\" \"N\" \"Y\" ...\n $ Oldpeak       : num [1:746] 0 1 0 1.5 0 0 0 0 1.5 0 ...\n $ HeartDisease  : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 1 1 2 1 ...\n\n# split data\ntraining_set_glm &lt;-  data_logistic[trainIndex, ]\ntest_set_glm &lt;- data_logistic[-trainIndex, ]\n\n#check data\ndim(training_set_glm)\n\n[1] 597  11\n\ndim(test_set_glm)\n\n[1] 149  11\n\n\n\nLogistic Regression Model 1\nThe EDA results show that whether a person has HeartDisease is related to his/her ExerciseAngina, Oldpeak, ChestPainType, MaxHR, Sex, and Age. First, let’s just fit the linear model with these predictors.\n\nset.seed(55807162)\n# fit model 1\nlogistic_M1_fit &lt;- train(HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age, \n                         data = training_set_glm, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         preProcess = c(\"center\", \"scale\"), #preprocess the data\n                         trControl=trctrl)\nsummary(logistic_M1_fit)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7275  -0.5702  -0.1881   0.5406   2.7007  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -0.1207     0.1191  -1.014  0.31079    \nExerciseAnginaY    0.5976     0.1290   4.633 3.60e-06 ***\nOldpeak            0.7640     0.1469   5.200 2.00e-07 ***\nChestPainTypeATA  -0.7867     0.1377  -5.713 1.11e-08 ***\nChestPainTypeNAP  -0.6640     0.1233  -5.385 7.25e-08 ***\nChestPainTypeTA   -0.3406     0.1113  -3.059  0.00222 ** \nMaxHR             -0.1102     0.1304  -0.845  0.39831    \nSexM               0.7252     0.1297   5.592 2.24e-08 ***\nAge                0.3848     0.1312   2.933  0.00335 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 826.40  on 596  degrees of freedom\nResidual deviance: 478.36  on 588  degrees of freedom\nAIC: 496.36\n\nNumber of Fisher Scoring iterations: 5\n\n# predict the test set with the trained model\ntest_M1_pred &lt;- predict(logistic_M1_fit, newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_M1&lt;-confusionMatrix(test_M1_pred, test_set_glm$HeartDisease)\n\n\n\nLogistic Regression Model 2\nSince model 1 shows MaxHR’s impact is not significant. Also, the correlation between Age and MaxHR is relatively high. The multicolinearity might exist. Let’s drop MaxHR from the model.\n\nset.seed(55807163)\n# fit model 2\nlogistic_M2_fit &lt;- train(HeartDisease ~ ExerciseAngina + ChestPainType + Oldpeak + Age + Sex,\n                         data = training_set_glm, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         trControl=trctrl)\nsummary(logistic_M2_fit)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7287  -0.5614  -0.1902   0.5428   2.6800  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -4.00879    0.77494  -5.173 2.30e-07 ***\nExerciseAnginaY   1.27059    0.25936   4.899 9.63e-07 ***\nChestPainTypeATA -1.94664    0.32986  -5.901 3.60e-09 ***\nChestPainTypeNAP -1.62277    0.28999  -5.596 2.20e-08 ***\nChestPainTypeTA  -1.53610    0.48301  -3.180 0.001472 ** \nOldpeak           0.71386    0.13734   5.198 2.02e-07 ***\nAge               0.04401    0.01322   3.329 0.000872 ***\nSexM              1.70858    0.29985   5.698 1.21e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 826.40  on 596  degrees of freedom\nResidual deviance: 479.07  on 589  degrees of freedom\nAIC: 495.07\n\nNumber of Fisher Scoring iterations: 5\n\n# predict the test set with the trained model\ntest_M2_pred &lt;- predict(logistic_M2_fit, newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_M2&lt;-confusionMatrix(test_M2_pred, test_set_glm$HeartDisease)\n\n\n\nLogistic Regression Model 3\nLastly, since EDA shows the correlation between ExerciseAngina and ChestPainType is relatively high. Let’s see the model fit if we add the interaction term of these two.\n\nset.seed(55807164)\n# fit model 3\nlogistic_M3_fit &lt;- train(HeartDisease ~ Oldpeak + Sex + Age + ExerciseAngina + ChestPainType + ExerciseAngina:ChestPainType, \n                         data = training_set_glm, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         trControl=trctrl)\nsummary(logistic_M3_fit)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7650  -0.5646  -0.1808   0.5302   2.6760  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                        -4.14538    0.79954  -5.185 2.16e-07 ***\nOldpeak                             0.71497    0.13869   5.155 2.53e-07 ***\nSexM                                1.75163    0.30511   5.741 9.41e-09 ***\nAge                                 0.04491    0.01331   3.375 0.000738 ***\nExerciseAnginaY                     1.39605    0.33316   4.190 2.79e-05 ***\nChestPainTypeATA                   -1.98753    0.39304  -5.057 4.26e-07 ***\nChestPainTypeNAP                   -1.51758    0.34827  -4.357 1.32e-05 ***\nChestPainTypeTA                    -1.21861    0.49680  -2.453 0.014171 *  \n`ExerciseAnginaY:ChestPainTypeATA`  0.28370    0.76217   0.372 0.709723    \n`ExerciseAnginaY:ChestPainTypeNAP` -0.32499    0.62056  -0.524 0.600484    \n`ExerciseAnginaY:ChestPainTypeTA`  -2.55065    1.38044  -1.848 0.064643 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 826.40  on 596  degrees of freedom\nResidual deviance: 474.98  on 586  degrees of freedom\nAIC: 496.98\n\nNumber of Fisher Scoring iterations: 5\n\n# predict the test set with the trained model\ntest_M3_pred &lt;- predict(logistic_M3_fit, newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_M3&lt;-confusionMatrix(test_M3_pred, test_set_glm$HeartDisease)\n\n\n\nCompare the three models\n\nlist(logistic_M1 = confusionMatrix_M1$overall[1], \n     logistic_M2 = confusionMatrix_M2$overall[1], \n     logistic_M3 = confusionMatrix_M3$overall[1])\n\n$logistic_M1\n Accuracy \n0.8456376 \n\n$logistic_M2\n Accuracy \n0.8322148 \n\n$logistic_M3\n Accuracy \n0.8255034 \n\n\nAs shown above, Model 1 has the best performance/accuracy. Model 1 is HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age. It seems drop the insignificant predictor from the model or add interaction term does not help.\n\n\n\nTree Models\nAs with logistic regression, tree models can accept factor/character variables as predictors. Thus, we will use the same data as we used before (data_logistic, training_set_glm, test_set_glm). We will fit the model with ExerciseAngina, Oldpeak, ChestPainType, MaxHR, Sex, and Age.\n\nclassification tree model\n\nset.seed(55806175)\nclassification_tree_fit &lt;- train(HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age,\n                            data = training_set_glm,\n                            method = \"rpart\",\n                            trControl = trctrl,\n                            tuneGrid = expand.grid(cp = seq(0, 0.1, by = 0.001)))\nclassification_tree_fit\n\nCART \n\n597 samples\n  6 predictor\n  2 classes: '0', '1' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 538, 538, 536, 538, 537, 538, ... \nResampling results across tuning parameters:\n\n  cp     Accuracy   Kappa    \n  0.000  0.7890158  0.5776630\n  0.001  0.7901087  0.5799620\n  0.002  0.7946376  0.5888995\n  0.003  0.7946376  0.5888995\n  0.004  0.7986188  0.5964692\n  0.005  0.7958410  0.5908318\n  0.006  0.7941275  0.5870607\n  0.007  0.7958036  0.5900594\n  0.008  0.7963501  0.5909301\n  0.009  0.7969150  0.5920416\n  0.010  0.7996558  0.5974800\n  0.011  0.8013507  0.6004931\n  0.012  0.7895610  0.5766936\n  0.013  0.7895610  0.5766936\n  0.014  0.7822911  0.5621668\n  0.015  0.7811611  0.5597856\n  0.016  0.7789012  0.5552961\n  0.017  0.7789012  0.5552961\n  0.018  0.7738535  0.5451624\n  0.019  0.7732886  0.5439880\n  0.020  0.7649907  0.5272386\n  0.021  0.7649907  0.5272386\n  0.022  0.7605275  0.5179588\n  0.023  0.7605275  0.5179588\n  0.024  0.7599813  0.5167680\n  0.025  0.7599813  0.5167680\n  0.026  0.7611018  0.5185126\n  0.027  0.7611018  0.5185126\n  0.028  0.7632876  0.5226532\n  0.029  0.7632876  0.5226532\n  0.030  0.7644176  0.5247918\n  0.031  0.7644176  0.5247918\n  0.032  0.7666034  0.5288971\n  0.033  0.7666034  0.5288971\n  0.034  0.7666034  0.5288971\n  0.035  0.7666034  0.5288971\n  0.036  0.7687521  0.5327472\n  0.037  0.7687521  0.5327472\n  0.038  0.7687521  0.5327472\n  0.039  0.7687521  0.5327472\n  0.040  0.7687521  0.5327472\n  0.041  0.7687521  0.5327472\n  0.042  0.7687521  0.5327472\n  0.043  0.7687521  0.5326754\n  0.044  0.7687521  0.5326754\n  0.045  0.7687521  0.5326754\n  0.046  0.7687521  0.5326754\n  0.047  0.7687521  0.5326754\n  0.048  0.7687521  0.5326754\n  0.049  0.7687521  0.5326754\n  0.050  0.7687521  0.5326754\n  0.051  0.7687521  0.5326754\n  0.052  0.7687521  0.5326754\n  0.053  0.7687521  0.5326754\n  0.054  0.7687521  0.5326754\n  0.055  0.7687521  0.5326754\n  0.056  0.7687521  0.5326754\n  0.057  0.7687521  0.5326754\n  0.058  0.7687521  0.5326754\n  0.059  0.7687521  0.5326754\n  0.060  0.7687521  0.5326754\n  0.061  0.7687521  0.5326754\n  0.062  0.7687521  0.5326754\n  0.063  0.7687521  0.5326754\n  0.064  0.7687521  0.5326754\n  0.065  0.7687521  0.5326754\n  0.066  0.7687521  0.5326754\n  0.067  0.7687521  0.5326754\n  0.068  0.7687521  0.5326754\n  0.069  0.7687521  0.5326754\n  0.070  0.7687521  0.5326754\n  0.071  0.7687521  0.5326754\n  0.072  0.7687521  0.5326754\n  0.073  0.7687521  0.5326754\n  0.074  0.7687521  0.5326754\n  0.075  0.7687521  0.5326754\n  0.076  0.7687521  0.5326754\n  0.077  0.7687521  0.5326754\n  0.078  0.7687521  0.5326754\n  0.079  0.7687521  0.5326754\n  0.080  0.7687521  0.5326754\n  0.081  0.7687521  0.5326754\n  0.082  0.7687521  0.5326754\n  0.083  0.7687521  0.5326754\n  0.084  0.7687521  0.5326754\n  0.085  0.7687521  0.5326754\n  0.086  0.7687521  0.5326754\n  0.087  0.7687521  0.5326754\n  0.088  0.7687521  0.5326754\n  0.089  0.7687521  0.5326754\n  0.090  0.7687521  0.5326754\n  0.091  0.7687521  0.5326754\n  0.092  0.7687521  0.5326754\n  0.093  0.7687521  0.5326754\n  0.094  0.7687521  0.5326754\n  0.095  0.7687521  0.5326754\n  0.096  0.7687521  0.5326754\n  0.097  0.7687521  0.5326754\n  0.098  0.7687521  0.5326754\n  0.099  0.7687521  0.5326754\n  0.100  0.7687521  0.5326754\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.011.\n\n# predict the test set with the trained model\ntest_classification_tree_pred &lt;- predict(classification_tree_fit, \n                                         newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_classification_tree &lt;-confusionMatrix(test_classification_tree_pred,\n                                                      test_set_glm$HeartDisease)\n\n\n\nrandom forest model\n\nset.seed(55806176)\nrandom_forest_fit &lt;- train(HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age,\n                           data = training_set_glm,\n                           method = \"rf\",\n                           trControl = trctrl,\n                           tuneGrid = expand.grid(mtry = 1:(ncol(data)/3)))\nrandom_forest_fit\n\nRandom Forest \n\n597 samples\n  6 predictor\n  2 classes: '0', '1' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 538, 538, 537, 538, 537, 537, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  1     0.8123767  0.6225924\n  2     0.7945780  0.5873380\n  3     0.7895114  0.5777086\n  4     0.7867616  0.5722823\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 1.\n\n# predict the test set with the trained model\ntest_random_forest_pred &lt;- predict(random_forest_fit, \n                                   newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_random_forest &lt;-confusionMatrix(test_random_forest_pred,\n                                                test_set_glm$HeartDisease)\n\n\n\nboosted tree\n\nset.seed(55806177)\n\nboosted_tree_fit &lt;- train(HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age,\n                     data = training_set_glm,\n                     method = \"gbm\",\n                     trControl = trctrl,\n                     tuneGrid = expand.grid(n.trees = c(25, 50, 100, 200), # Number of trees (boosting iterations) in the GBM model\n                                            interaction.depth = c(1, 2, 3), # Maximum depth of variable interactions in each tree\n                                            shrinkage = 0.1, # Shrinkage parameter (learning rate) to control overfitting\n                                            n.minobsinnode = 10), # Minimum number of observations in each terminal node of a tree\n                     verbose = FALSE ) # Control verbosity of the GBM model training\nboosted_tree_fit\n\nStochastic Gradient Boosting \n\n597 samples\n  6 predictor\n  2 classes: '0', '1' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 538, 537, 537, 538, 538, 537, ... \nResampling results across tuning parameters:\n\n  interaction.depth  n.trees  Accuracy   Kappa    \n  1                   25      0.8016213  0.6007686\n  1                   50      0.8067597  0.6114440\n  1                  100      0.8056386  0.6096023\n  1                  200      0.8005168  0.5995168\n  2                   25      0.8028065  0.6034439\n  2                   50      0.8044813  0.6073851\n  2                  100      0.8005548  0.5995123\n  2                  200      0.7993778  0.5975030\n  3                   25      0.8011766  0.6006767\n  3                   50      0.8027952  0.6041374\n  3                  100      0.7949603  0.5884366\n  3                  200      0.7927752  0.5843054\n\nTuning parameter 'shrinkage' was held constant at a value of 0.1\n\nTuning parameter 'n.minobsinnode' was held constant at a value of 10\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were n.trees = 50, interaction.depth =\n 1, shrinkage = 0.1 and n.minobsinnode = 10.\n\n# predict the test set with the trained model\ntest_boosted_tree_pred &lt;- predict(boosted_tree_fit, \n                                  newdata = test_set_glm)\n\n# test the model performance with the confusion matrix\nconfusionMatrix_boosted_tree &lt;-confusionMatrix(test_boosted_tree_pred,\n                                               test_set_glm$HeartDisease)\n\n\n\nCompare the three tree models\n\nlist(classification_tree = confusionMatrix_classification_tree$overall[1], \n     random_forest = confusionMatrix_random_forest$overall[1], \n     boosted_tree = confusionMatrix_boosted_tree$overall[1])\n\n$classification_tree\n Accuracy \n0.7919463 \n\n$random_forest\n Accuracy \n0.8322148 \n\n$boosted_tree\n Accuracy \n0.8322148 \n\n\nIt seems the random forest model and boosted tree model perform equally better than the classification tree model.\n\n\n\nWrap up\nLet’s recall all models we fitted and compare their performance!\n\nlist(kNN = confusionMatrix_kNN$overall[1],\n     logistic_M1 = confusionMatrix_M1$overall[1], \n     logistic_M2 = confusionMatrix_M2$overall[1], \n     logistic_M3 = confusionMatrix_M3$overall[1],\n     classification_tree = confusionMatrix_classification_tree$overall[1], \n     random_forest = confusionMatrix_random_forest$overall[1], \n     boosted_tree = confusionMatrix_boosted_tree$overall[1])\n\n$kNN\n Accuracy \n0.7986577 \n\n$logistic_M1\n Accuracy \n0.8456376 \n\n$logistic_M2\n Accuracy \n0.8322148 \n\n$logistic_M3\n Accuracy \n0.8255034 \n\n$classification_tree\n Accuracy \n0.7919463 \n\n$random_forest\n Accuracy \n0.8322148 \n\n$boosted_tree\n Accuracy \n0.8322148 \n\n\nOverall, the logistic model 1 perform the best. Its accuracy rate is the highest, which is 84.56%. As a reminder, logistic model 1 is HeartDisease ~ ExerciseAngina + Oldpeak + ChestPainType + MaxHR + Sex + Age."
  }
]